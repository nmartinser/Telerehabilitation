{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML para predecir el gesto\n",
    "\n",
    "Creación y evaluación de modelos de Machine Learning para predecir qué gesto está realizando el paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importar librerías---------\n",
    "# Manipular los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# scikit-learn (ML en python)\n",
    "## Procesar el dataset\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "## Modelos ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Evaluación de los modelos\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "## Hiperparametrizacion\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "## Seleccion de variables\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFECV # recursive\n",
    "\n",
    "# Para ignorar los FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Importar los datos-----------\n",
    "# Dataframe medidas calculadas por repetición\n",
    "df = pd.read_csv('../csvFiles/medidasPerRepetition.csv', dtype=object) # salida de leer_dataset.ipynb\n",
    "df.head() # visualizacion de la cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame({'Clasificadores': ['K-Neighbors',\n",
    "                                            'Decision tree',\n",
    "                                            'Naive Bayes',\n",
    "                                            'Suport Vector Machine',\n",
    "                                            'Random Forest']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Codificar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Preparar el dataset-------\n",
    "encoder = OrdinalEncoder(categories=[list(set(df[\"Position\"].values))])\n",
    "encoder.fit(df[[\"Position\"]])\n",
    "df[\"Position\"] = encoder.transform(df[[\"Position\"]])\n",
    "\n",
    "# pasar variable obj to numeric\n",
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dividir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dejar dos pacientes como test\n",
    "\n",
    "test_df = df.loc[(df.SubjectID==101) | (df.SubjectID==105) | (df.SubjectID==201) | (df.SubjectID==202) | (df.SubjectID==301) | (df.SubjectID==302)]\n",
    "train_df = df.loc[(df.SubjectID!=101) & (df.SubjectID!=105) & (df.SubjectID!=201) & (df.SubjectID!=202) & (df.SubjectID!=301) & (df.SubjectID!=302)] \n",
    "\n",
    "train_X = train_df.drop(['GestureLabel'], axis=1)\n",
    "train_y=pd.DataFrame(train_df['GestureLabel']) \n",
    "test_X= test_df.drop(['GestureLabel'], axis=1) \n",
    "test_y =pd.DataFrame(test_df['GestureLabel'])\n",
    "\n",
    "# # Convertimos los df de target (y) a 1-d\n",
    "train_y = train_y.values.ravel()\n",
    "test_y = test_y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelos de ML\n",
    "Se ha creado una función para entrenar y evaluar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Funcion para evaluar los modelos-----------\n",
    "def test_models(modelos, tX, ty, df, column_name):\n",
    "   new_evaluation = []\n",
    "   for modelo in modelos:\n",
    "      prediction = modelo.predict(tX) #  predicciones en los datos de prueba\n",
    "      report = classification_report(ty, prediction, zero_division=0) # informe de evaluación\n",
    "      score = f1_score(test_y, prediction, average='weighted', zero_division=0) \n",
    "      new_evaluation.append(score)\n",
    "      print(f\"\\nModelo: {modelo.__class__.__name__}\") \n",
    "      print(report) \n",
    "   df.loc[:, column_name] = new_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Función matriz de confusión-----\n",
    "def plot_confusion_matrix(modelo, tX, ty, ax=None):\n",
    "    \"\"\"\n",
    "    Grafica la matriz de confusión para un modelo dado.\n",
    "\n",
    "    Parámetros:\n",
    "    * modelo: El modelo de clasificación entrenado.\n",
    "    * tX: Los datos de prueba.\n",
    "    * ty: Los valores reales del target para los datos de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    prediction = modelo.predict(tX)\n",
    "    cm = confusion_matrix(ty, prediction)\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "    ax.set_title('Matriz de confusión ' + modelo.__class__.__name__)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier() # K-Neighbors classifier\n",
    "dtree = DecisionTreeClassifier() # Decision tree\n",
    "nb = GaussianNB() # Naive Bayes\n",
    "svm = SVC() # Suport Vector Machine\n",
    "rf = RandomForestClassifier()  # Random Forest\n",
    "\n",
    "models = [knn, dtree, nb, svm, rf]\n",
    "\n",
    "for modelo in models:\n",
    "    modelo.fit(train_X, train_y) # entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "\n",
    "common_params = {\n",
    "    \"X\": train_X,\n",
    "    \"y\": train_y,\n",
    "    \"groups\": train_X['SubjectID'],\n",
    "    # \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": LeaveOneGroupOut(),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 4,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "for idx, estimator in enumerate(models):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "    handles, label = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[:2], [\"Resultado del entrenamiento\", \"Resultado de la validación\"])\n",
    "    ax.set_title(f\"Curva de aprendizaje de {estimator.__class__.__name__}\")\n",
    "    ax.set_ylim(0.5, 1.01)\n",
    "fig.delaxes(axes.flatten()[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamiento + evaluación\n",
    "test_models(models, test_X, test_y, test_result, 'Modelos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hipermetrización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------Parametros---------------\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [6, 7, 8],\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'leaf_size': (3, 4, 5, 6, 8),\n",
    "    'p': (1,2),\n",
    "    'metric': ('minkowski', 'chebyshev')\n",
    "}\n",
    "\n",
    "param_grid_dtree = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 40, 50, 60],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 7],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_nb = {'var_smoothing': np.logspace(0, -8, num=100)}\n",
    "\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 0.2, 0.3],#np.linspace(0, 1, num=10),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 50, 60],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 5, 6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_hiperparametrizacion(X, y):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    gs_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=logo, scoring='accuracy', n_jobs=-1)\n",
    "    gs_dtree = GridSearchCV(DecisionTreeClassifier(), param_grid_dtree, cv=logo, scoring='accuracy', n_jobs=-1)\n",
    "    gs_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=logo, scoring='accuracy', n_jobs=-1)\n",
    "    gs_svm = GridSearchCV(SVC(), param_grid_svm, cv=logo, scoring='accuracy', n_jobs=-1)\n",
    "    gs_rf = RandomizedSearchCV(RandomForestClassifier(), param_grid_rf, cv=logo, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    subject_ids = X['SubjectID']\n",
    "    \n",
    "    modelos = [gs_knn, gs_dtree, gs_nb, gs_svm, gs_rf]\n",
    "\n",
    "\n",
    "    best_models = []\n",
    "    for modelo in modelos:\n",
    "        modelo.fit(X, y, groups=subject_ids)\n",
    "        best_modelo = modelo.best_estimator_\n",
    "        print(f\"\\nModelo: {modelo.estimator.__class__.__name__}\") \n",
    "        print(\"Mejores parámetros: \", modelo.best_params_)\n",
    "        print(\"Mejor resultado: \", modelo.best_score_)\n",
    "        best_models.append(best_modelo)\n",
    "        LearningCurveDisplay.from_estimator(best_modelo, \n",
    "                                            X=X,\n",
    "                                            y=y,\n",
    "                                            groups=subject_ids,\n",
    "                                            cv=logo,\n",
    "                                            score_type=\"both\",\n",
    "                                            n_jobs=4,\n",
    "                                            line_kw={\"marker\": \"o\"},\n",
    "                                            std_display_style=\"fill_between\",\n",
    "                                            score_name=\"Accuracy\"\n",
    "                                        )\n",
    "         \n",
    "        plt.legend([\"Resultado del entrenamiento\", \"Resultado de la validación\"])\n",
    "        plt.title(f\"Curva de aprendizaje de {modelo.estimator.__class__.__name__}\")\n",
    "        plt.show()\n",
    "\n",
    "    return best_models\n",
    "    \n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "best_models = aplicar_hiperparametrizacion(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models(best_models, test_X, test_y, test_result, 'Hiperparametrización (H)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------matriz de confusión-----\n",
    "num_models = len(best_models)\n",
    "num_cols = 2  # Number of matrices per row\n",
    "num_rows = (num_models + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 6*num_rows))\n",
    "\n",
    "\n",
    "for i, modelo in enumerate(best_models):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    ax = axes[row, col]\n",
    "    plot_confusion_matrix(modelo, test_X, test_y, ax=ax)\n",
    "    # Hide unused subplots\n",
    "for i in range(num_models, num_rows * num_cols):\n",
    "    axes.flatten()[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = train_X['SubjectID']\n",
    "\n",
    "\n",
    "# Definimos feature Selection K=50 (selecciona entonces las 50 variables que considere mas importantes)\n",
    "feature_selection = SelectKBest(k=50)\n",
    "\n",
    "# Fit Feature Selection (entrena y hace una tranfosmada)\n",
    "selected_features = feature_selection.fit_transform(train_X.drop(columns=['SubjectID']), train_y)\n",
    "\n",
    "# Selecionamos las características mas relevantes para nuestro problema\n",
    "selected = feature_selection.get_support(indices=True)\n",
    "\n",
    "print(train_X.columns[selected])\n",
    "\n",
    "# Reduce train_X to the selected features with .transform(X)\n",
    "#creamos un data frame vacio para hacer una tabla donde esten \n",
    "# las variables con la trsnformada de la X.\n",
    "# esto elimina las variales que no nos intersan.\n",
    "\n",
    "\n",
    "X_fs = pd.DataFrame(selected_features,\n",
    "                 columns=train_X.drop(columns=['SubjectID']).columns[selected])\n",
    "\n",
    "X_fs['SubjectID'] = subject_id.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Entrenar con las variables sleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación de los modelos\n",
    "knn_fs = KNeighborsClassifier() # K-Neighbors classifier\n",
    "dtree_fs = DecisionTreeClassifier() # Decision tree\n",
    "nb_fs = GaussianNB() # Naive Bayes\n",
    "svm_fs = SVC() # Suport Vector Machine\n",
    "rf_fs = RandomForestClassifier()  # Random Forest\n",
    "\n",
    "models_fs = [knn_fs, dtree_fs, nb_fs, svm_fs, rf_fs]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "for modelo in models_fs:\n",
    "        print(f\"\\nModelo: {modelo.__class__.__name__}\")\n",
    "        modelo.fit(X_fs, train_y)\n",
    "        scores = cross_val_score(modelo, X_fs, train_y, groups=X_fs['SubjectID'],  scoring='accuracy', cv=logo)\n",
    "        print(\"%0.2f accuracy con una derivación estandar de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subject_id = test_X['SubjectID']\n",
    "\n",
    "\n",
    "selected_features_test = feature_selection.transform(test_X.drop(columns=['SubjectID']))\n",
    "\n",
    "X_fs_test = pd.DataFrame(selected_features_test, columns=test_X.drop(columns=['SubjectID']).columns[selected])\n",
    "\n",
    "X_fs_test['SubjectID'] = test_subject_id.values\n",
    "\n",
    "test_models(models_fs, X_fs_test, test_y, test_result, 'Selección de variables (FS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelo in best_models:\n",
    "    modelo.fit(X_fs, train_y)\n",
    "test_models(best_models, X_fs_test, test_y, test_result, 'H + Fs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_rfe = DecisionTreeClassifier() # Decision tree\n",
    "rf_rfe = RandomForestClassifier(n_estimators = 5)  # Random Forest\n",
    "\n",
    "models_with_coef = [dtree_rfe, rf_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccion_variables(models, X, y):\n",
    "    for model in models:\n",
    "        rfecv = RFECV(\n",
    "            estimator=model,\n",
    "            scoring=\"accuracy\",\n",
    "            cv = LeaveOneGroupOut(),\n",
    "            n_jobs=-1 # Number of cores to run in parallel while fitting across folds. \n",
    "        )\n",
    "        rfecv.fit(X, y, groups=X['SubjectID'])\n",
    "        print(f\"\\nModelo: {rfecv.estimator.__class__.__name__}\") \n",
    "        print(f\"Número óptimo de características: {rfecv.n_features_}\")\n",
    "        selected = rfecv.get_feature_names_out()\n",
    "        print(selected)\n",
    "        print(rfecv.score)\n",
    "        cv_results = pd.DataFrame(rfecv.cv_results_)\n",
    "        plt.title(f\"RFECV {rfecv.estimator.__class__.__name__}\")\n",
    "        plt.xlabel(\"Número de características\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.plot(range(1, len(cv_results['mean_test_score']) + 1), cv_results['mean_test_score'])\n",
    "        plt.show()\n",
    "\n",
    "seleccion_variables(models_with_coef, train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe to transform it into long format\n",
    "df_melted = pd.melt(test_result, id_vars=['Clasificadores'], value_vars=['Modelos', 'Hiperparametrización (H)', 'Selección de variables (FS)', 'H + Fs'],\n",
    "                    var_name='score_type', value_name='score')\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.lineplot(x='score_type', y='score', hue='Clasificadores', data=df_melted, marker='o', palette='Set1')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Clasificador')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-Scores por Clasificador')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
