{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Clasificación de la ejecución del movimiento\n",
    "**Descripción**\\\n",
    "En esta segunda fase del proyecto, el objetivo es evaluar la correcta ejecución de los gestos identificados en la Fase 1. Después de haber determinado el mejor modelo para reconocer el tipo de gesto realizado por el paciente, ahora buscamos identificar si cada gesto se realiza correctamente o no.\\\n",
    "Este notebook aborda los siguientes aspectos:\n",
    "* Creación de modelos: para cada tipo de gesto identificado en la Fase 1, se desarrollan modelos de clasificación separados, para determinar si un gesto es ejecutado de manera correcta o incorrecta\n",
    "* Evaluación de la ejecución.\n",
    "\n",
    "**Entrada**\n",
    "* Datos de gestos procesados en el archivo ``medidasPerRepetition.csv``.\n",
    "\n",
    "**Salida**\n",
    "* Los resultados detallados del ajuste de modelos tras aplicar varias técnica de balanceo de datos se almacenan en el archivo ``Results_imblearn.txt``. \n",
    "\n",
    "**Índice**\n",
    "1. [Preprocesado](#1-preprocesado)\n",
    "2. [Funciones adicionales](#2-funciones-adicionales)\n",
    "3. [Balanceo de datos y modelos de clasificación](#3-balanceo-de-datos-y-modelos-de-clasificación)\n",
    "4. [Pipeline](#4-pipeline)\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importar librerías---------\n",
    "# Manipular los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# scikit-learn (ML en python)\n",
    "## Procesar el dataset\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut # LeavePGroupsOut\n",
    "## Modelos ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## Evaluación de los modelos\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "## Hiperparametrizacion\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Class imbalance\n",
    "from imblearn.under_sampling import NearMiss, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "## Seleccion de variables\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Para ignorar los Warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning \n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "warnings.simplefilter(action = 'ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Importar los datos-----------\n",
    "# Dataframe medidas calculadas por repetición\n",
    "df = pd.read_csv('../Resultados/medidasPerRepetition.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## 1. Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Preparar el dataset-------\n",
    "encoder = OrdinalEncoder(categories=[list(set(df[\"Position\"].values))])\n",
    "encoder.fit(df[[\"Position\"]])\n",
    "df[\"Position\"] = encoder.transform(df[[\"Position\"]])\n",
    "\n",
    "# pasar variable obj to numeric\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# cmabiar las poorly executed to incorrectly executed\n",
    "df[df['CorrectLabel']==3] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## 2. Funciones adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Funciones--------\n",
    "\n",
    "# dividir en test y train df_gestures\n",
    "def split_df_gestures(df:pd.DataFrame, target: str):\n",
    "  \"\"\"\n",
    "  Divide un DataFrame en conjuntos de entrenamiento y prueba basados en los valores de 'SubjectID'.\n",
    "\n",
    "  Parámetros\n",
    "  ----------\n",
    "  df : pd.DataFrame\n",
    "      DataFrame que contiene los datos completos incluyendo características y el target.\n",
    "  target : str\n",
    "      Nombre de la columna objetivo que contiene las etiquetas de la clase.\n",
    "\n",
    "  Return\n",
    "  -------\n",
    "  X_train : pd.DataFrame\n",
    "      Conjunto de datos de entrenamiento con las características (sin la columna objetivo).\n",
    "  X_test : pd.DataFrame\n",
    "      Conjunto de datos de prueba con las características (sin la columna objetivo).\n",
    "  y_train : np.ndarray\n",
    "      Array 1D con las etiquetas del conjunto de entrenamiento.\n",
    "  y_test : np.ndarray\n",
    "      Array 1D con las etiquetas del conjunto de prueba.\n",
    "  \"\"\"\n",
    "  # Selecciona los datos de prueba (varios sujetos)\n",
    "  test_df = df.loc[(df.SubjectID==101) | (df.SubjectID==105) | (df.SubjectID==201) | (df.SubjectID==202) | (df.SubjectID==301) | (df.SubjectID==302)]\n",
    "  \n",
    "  # Selecciona los datos de entrenamiento excluyendo los mismos sujetos\n",
    "  train_df = df.loc[(df.SubjectID!=101) & (df.SubjectID!=105) & (df.SubjectID!=201) & (df.SubjectID!=202) & (df.SubjectID!=301) & (df.SubjectID!=302)]\n",
    "\n",
    "  # Separa las características y las etiquetas en el conjunto de entrenamiento\n",
    "  X_train = train_df.drop([target], axis=1)  \n",
    "  y_train = pd.DataFrame(train_df[target])   \n",
    "\n",
    "  # Separa las características y las etiquetas en el conjunto de prueba\n",
    "  X_test = test_df.drop([target], axis=1)  \n",
    "  y_test = pd.DataFrame(test_df[target])   \n",
    "\n",
    "  # Convierte los DataFrames de etiquetas a arrays 1D\n",
    "  y_train = y_train.values.ravel()\n",
    "  y_test = y_test.values.ravel()\n",
    "\n",
    "  # Devuelve los conjuntos de entrenamiento y prueba\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Para entrenar los modelos de ML\n",
    "def aplicar_modelos(X: pd.DataFrame, y: np.ndarray, tX: pd.DataFrame, ty: np.ndarray, file):\n",
    "    \"\"\"\n",
    "    Entrena y evalua una lista de modelos deaprendizaje automático,\\\\\n",
    "    guardando los resultados en una archivo\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Conjunto de datos de entrenamiento con las características (variables independientes).\n",
    "    y : np.ndarray\n",
    "        Array con las etiquetas (valores de salida) del conjunto de entrenamiento.\n",
    "    tX : pd.DataFrame\n",
    "        Conjunto de datos de prueba con las características.\n",
    "    ty : np.ndarray\n",
    "        Array con las etiquetas verdaderas del conjunto de prueba.\n",
    "    file : archivo\n",
    "        Objeto de archivo abierto para escribir los resultados.\n",
    "    \"\"\"\n",
    "    # creación de los modelos\n",
    "    knn = KNeighborsClassifier()  # K-Neighbors classifier\n",
    "    dtree = DecisionTreeClassifier()  # Decision tree\n",
    "    nb = GaussianNB()  # Naive Bayes\n",
    "    svm = SVC()  # Support Vector Machine\n",
    "    rf = RandomForestClassifier()  # Random Forest\n",
    "    lr = LogisticRegression()  # Logistic Regression\n",
    "\n",
    "    models = [knn, dtree, nb, svm, rf, lr]\n",
    "\n",
    "    # Método de validación cruzada Leave-One-Group-Out basado en SubjectID\n",
    "    logo = LeaveOneGroupOut()\n",
    "    grupos = X['SubjectID']\n",
    "\n",
    "    # Iteramos sobre los modelos\n",
    "    for modelo in models:\n",
    "        # Evaluación de modelos mediante validación cruzada\n",
    "        accuracy_scores = cross_val_score(modelo, X, y, groups=grupos, cv=logo, scoring='accuracy')\n",
    "        f1_scores = cross_val_score(modelo, X, y, groups=grupos, cv=logo, scoring='f1')\n",
    "        \n",
    "        # Escribiendo los resultados de la validación cruzada en el archivo\n",
    "        file.write(f\"\\nModelo: {modelo.__class__.__name__}\\n\")\n",
    "        file.write(f\"Precision media: {accuracy_scores.mean():.2f} con una desviacion estandar de {accuracy_scores.std():.2f}\\n\")\n",
    "        file.write(f\"F1-score media: {f1_scores.mean():.2f} con una desviacion estandar de {f1_scores.std():.2f}\\n\")\n",
    "\n",
    "        # Evaluación final en el conjunto de prueba\n",
    "        modelo.fit(X, y)  # Entrenamos el modelo con todos los datos de entrenamiento\n",
    "        prediction = modelo.predict(tX)  # Predicciones en los datos de prueba\n",
    "        score = f1_score(ty, prediction, average='weighted', zero_division=0) \n",
    "        file.write(f\"Evaluacion en conjunto de prueba (F1-score ponderado): {score:.2f}\\n\")\n",
    "\n",
    "\n",
    "# Aplicar imbalance learn\n",
    "def aplicar_imblearn(X: pd.DataFrame, y: np.ndarray,  tX: pd.DataFrame, ty: np.ndarray, file):\n",
    "    \"\"\"\n",
    "    Aplica una lista de técnicas de balanceo de datos para abordar el desbalance de clases.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Conjunto de datos de entrenamiento con las características (variables independientes).\n",
    "    y : np.ndarray\n",
    "        Array con las etiquetas (valores de salida) del conjunto de entrenamiento.\n",
    "    tX : pd.DataFrame\n",
    "        Conjunto de datos de prueba con las características.\n",
    "    ty : np.ndarray\n",
    "        Array con las etiquetas verdaderas del conjunto de prueba.\n",
    "    file : archivo\n",
    "        Objeto de archivo abierto para escribir los resultados.\n",
    "    \"\"\"\n",
    "    # Definición de las técnicas de resampling de imbalanced-learn\n",
    "    nm1 = NearMiss(version=1, n_neighbors=2)  # Undersampling: NearMiss versión 1\n",
    "    enn = EditedNearestNeighbours()  # Undersampling: Edited Nearest Neighbours\n",
    "    adasyn = ADASYN(n_neighbors=2)  # Oversampling: Adaptive Synthetic Sampling (ADASYN)\n",
    "    smote = SMOTE(k_neighbors=2)  # Oversampling: Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "    smotetomek = SMOTETomek(smote=smote)  # Combinación de SMOTE y Tomek links (sobremuestreo y eliminación de ruido)\n",
    "    smote_enn = SMOTEENN(smote=smote)  # Combinación de SMOTE y Edited Nearest Neighbours (sobremuestreo y eliminación de ruido)\n",
    "\n",
    "    # Lista de técnicas de resampling\n",
    "    imblearns = [nm1, enn, adasyn, smote, smotetomek, smote_enn]\n",
    "\n",
    "    # Aplicación de cada técnica de resampling\n",
    "    for imblearn in imblearns:\n",
    "        # Resamplear los datos\n",
    "        X_im, y_im = imblearn.fit_resample(X, y)\n",
    "        \n",
    "        # Escribir resultados en el archivo\n",
    "        file.write(f\"\\n\\t- Tecnica de Resampling: {imblearn.__class__.__name__}\\n\")\n",
    "        file.write(f\"Distribucion de etiquetas antes del resampling: {Counter(y)}\\n\")\n",
    "        file.write(f\"Distribucion de etiquetas despues del resampling: {Counter(y_im)}\\n\")\n",
    "\n",
    "        # Aplicar modelos a los datos tras resamplear\n",
    "        aplicar_modelos(X_im, y_im, tX, ty, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## 3. Balanceo de datos y modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = df['GestureLabel'].unique()\n",
    "\n",
    "# Abre el archivo 'Results_imblearn.txt' para escribir los resultados\n",
    "with open('../Resultados/Results_imblearn.txt', 'w') as file:\n",
    "    # Itera sobre los gestos\n",
    "    for gesture in gestures:\n",
    "        # Filtra el DataFrame para obtener solo las filas correspondientes al gesto\n",
    "        df_gesture = df[df['GestureLabel'] == gesture]\n",
    "\n",
    "        # Divide el DataFrame en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = split_df_gestures(df_gesture, 'CorrectLabel')  \n",
    "\n",
    "        file.write(f'\\n------------ CLASIFICACION GESTO {gesture} -----------\\n')\n",
    "        aplicar_imblearn(X_train, y_train, X_test, y_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de evaluar los resultados en el archivo de salida ``Results_imblearn.txt``, se determinó que la técnica de balanceo de datos con mejor rendimiento es **SMOTETomek**. Por lo tanto, se utilizará esta técnica para generar y presentar los nuevos datos balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Aplicar SMOTETomek ---------------\n",
    "smotetomek = SMOTETomek(smote=SMOTE(k_neighbors=2))\n",
    "\n",
    "# Separar las características y las etiquetas\n",
    "X = df.drop(['CorrectLabel'], axis=1) \n",
    "y = pd.DataFrame(df['CorrectLabel'])\n",
    "\n",
    "# Resamplear los datos para balancear las clases\n",
    "X_resampled, y_resampled = smotetomek.fit_resample(X, y)\n",
    "\n",
    "balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "\n",
    "# Calcular la cantidad de sujetos únicos por gesto y estado de ejecución\n",
    "subject_count_per_gesture_correct = balanced_data.groupby([\"GestureLabel\", \"CorrectLabel\"])[\"SubjectID\"].nunique().reset_index()\n",
    "\n",
    "# Gráficar la distribución de sujetos después de aplicar SMOTETomek\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=\"GestureLabel\", y=\"SubjectID\", hue=\"CorrectLabel\",\n",
    "                 data=subject_count_per_gesture_correct, palette=\"Paired\")\n",
    "# Configurar el título y las etiquetas de los ejes\n",
    "ax.set_title(\"Distribución de los sujetos por gesto y estado de ejecución después de SMOTETomek\")\n",
    "ax.set_xlabel(\"Gesto\")\n",
    "ax.set_ylabel(\"Cantidad de sujetos\")\n",
    "\n",
    "# Configurar las etiquetas de la x-axis con los nombres de gestos \n",
    "gesture_labels = ['EFL', 'EFR', 'SFL', 'SFR', 'SAL', 'SAR', 'SFE', 'STL', 'STR']\n",
    "ax.set_xticklabels(gesture_labels)\n",
    "\n",
    "# Modificar las etiquetas de la leyenda\n",
    "legend_labels = ['correctly executed', 'incorrectly executed', 'poorly executed']\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=legend_labels, title='Execution')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Añadir etiquetas de conteo encima de cada barra en el gráfico\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## 4. Pipeline\n",
    "\n",
    "Creacióin de pipelines que incluyen técnicas de balanceo de datos, reducción de dimensión y clasificación. Además, se emplea ``RandomizedSearchCV`` para encontrar la mejor combinación de hiperparámetros para cada pipeline.\\\n",
    "Los modelos optimizados se evalúan utilizando métricas de rendimiento, incluyendo la curva ROC y el área bajo la curva (AUC), para cada gesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorar advertencias relacionadas con el ajuste del modelo\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "\n",
    "# Definir la malla de parámetros\n",
    "param_grid = [\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': [2, 3, 5], \n",
    "        'classifier__weights': ['uniform', 'distance'], \n",
    "        'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  \n",
    "    },\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [GaussianNB()]\n",
    "    },\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [SVC(probability=True)],\n",
    "        'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'classifier__C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [200, 300],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [LogisticRegression(max_iter=500)],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Definir Leave-One-Group-Out cross-validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Lista para almacenar los pipelines ajustados\n",
    "pipelines = []\n",
    "\n",
    "# Iterar sobre cada gesto único\n",
    "for gesture in gestures:\n",
    "\n",
    "    df_gesture = df[df['GestureLabel'] == gesture]\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = split_df_gestures(df_gesture, 'CorrectLabel')\n",
    "\n",
    "    print(f'\\n------------ CLASIFICACION GESTO {gesture} -----------\\n')\n",
    "\n",
    "    # Crear el pipeline con técnicas de balanceo, reducción de dimensión y modelo de clasificación\n",
    "    pipeline = Pipeline([('balance_data',  SMOTETomek(smote=SMOTE(k_neighbors=2))),\n",
    "                        ('reduce_dim', PCA()),\n",
    "                        ('classifier', KNeighborsClassifier(n_neighbors=2))])\n",
    "\n",
    "    # RandomizedSearchCVpara encontrar los mejores hiperparámetros\n",
    "    random = RandomizedSearchCV(pipeline, param_grid, cv=logo, n_jobs=-1)\n",
    "    random.fit(X_train, y_train, groups=X_train['SubjectID'])\n",
    "    # Mejor pipeline encontrado\n",
    "    best_pipeline = random.best_estimator_\n",
    "    pipelines.append(best_pipeline)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de entrenamiento y prueba\n",
    "    print('Training set score: ' + str(best_pipeline.score(X_train, y_train)))\n",
    "    print('Test set score: ' + str(best_pipeline.score(X_test, y_test)))\n",
    "    print(best_pipeline)\n",
    "\n",
    "    # Calcular la curva ROC\n",
    "    y_prob = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label = 2) \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Graficar la curva ROC\n",
    "    plt.figure()  \n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
