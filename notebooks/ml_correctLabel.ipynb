{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir si el ejercicio es correcto\n",
    "Aplicar Machine Learning para predecir si el paciente está realizando correctamente el ejercicio (clasificación binaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importar librerías---------\n",
    "# Manipular los datos\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# scikit-learn (ML en python)\n",
    "## Procesar el dataset\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Modelos ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## Evaluación de los modelos\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "## Hiperparametrizacion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "## Seleccion de variables\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFECV # recursive\n",
    "\n",
    "# Class imbalance\n",
    "from imblearn.under_sampling import NearMiss, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "## Seleccion de variables\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFECV # recursive\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Para ignorar los Warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning \n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "warnings.simplefilter(action = 'ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Importar los datos-----------\n",
    "# Dataframe medidas calculadas por repetición\n",
    "df = pd.read_csv('../csvFiles/medidasPerRepetition.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Preparar el dataset-------\n",
    "encoder = OrdinalEncoder(categories=[list(set(df[\"Position\"].values))])\n",
    "encoder.fit(df[[\"Position\"]])\n",
    "df[\"Position\"] = encoder.transform(df[[\"Position\"]])\n",
    "\n",
    "# pasar variable obj to numeric\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# cmabiar las poorly executed to incorrectly executed\n",
    "df[df['CorrectLabel']==3] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Funciones--------\n",
    "\n",
    "# Para entrenar los modelos de ML\n",
    "def aplicar_modelos(X: pd.DataFrame, y: pd.DataFrame, file):\n",
    "    \"\"\"\n",
    "    Aplica una lista de modelos de aprendizaje automático a los datos de prueba y muestra\n",
    "    los informes de evaluación.\n",
    "\n",
    "    Parámetros:\n",
    "    * X: datos de entrenamiento.\n",
    "    * y: target de entrenamiento.\n",
    "    * file: archivo para escribir los resultados.\n",
    "    \"\"\"\n",
    "    # creación de los modelos\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)  # K-Neighbors classifier\n",
    "    dtree = DecisionTreeClassifier()  # Decision tree\n",
    "    nb = GaussianNB()  # Naive Bayes\n",
    "    svm = SVC()  # Support Vector Machine\n",
    "    rf = RandomForestClassifier(n_estimators=5)  # Random Forest\n",
    "    lr = LogisticRegression(max_iter=500)  # Logistic Regression\n",
    "\n",
    "    models = [knn, dtree, nb, svm, rf, lr]\n",
    "\n",
    "    # Iteramos sobre los modelos\n",
    "    for modelo in models:\n",
    "        try:\n",
    "            accuracy_scores = cross_val_score(modelo, X, y, cv=5, scoring='accuracy')\n",
    "            recall_scores = cross_val_score(modelo, X, y, cv=5, scoring='recall')\n",
    "            file.write(f\"\\n\\t Modelo: {modelo.__class__.__name__}\\n\")\n",
    "            file.write(\"\\t%0.2f accuracy with a standard deviation of %0.2f\\n\" % (accuracy_scores.mean(), accuracy_scores.std()))\n",
    "            file.write(\"\\t%0.2f recall with a standard deviation of %0.2f\\n\" % (recall_scores.mean(), recall_scores.std()))            \n",
    "        except ValueError as e:\n",
    "            file.write(f\"Skipping {modelo.__class__.__name__} due to ERROR: {e}\\n\")\n",
    "\n",
    "# Aplicar imbalance learn\n",
    "def aplicar_imblearn(X, y, file):\n",
    "    nm1 = NearMiss(version=1, n_neighbors=2)\n",
    "    enn = EditedNearestNeighbours()\n",
    "    adasyn = ADASYN(n_neighbors=2)\n",
    "    smote = SMOTE(k_neighbors=2)\n",
    "    smotetomek = SMOTETomek(smote=smote)\n",
    "    smote_enn = SMOTEENN(smote=smote)\n",
    "\n",
    "    imblearns = [nm1, enn, adasyn, smote, smotetomek, smote_enn]\n",
    "    for imblearn in imblearns:\n",
    "        try:\n",
    "            X_im, y_im = imblearn.fit_resample(X, y)\n",
    "            file.write(f\"\\n- MODELO DE RESAMPLING: {imblearn.__class__.__name__}\\n\")\n",
    "            file.write(\"Distribution of class labels before resampling {}\\n\".format(Counter(y)))\n",
    "            file.write(\"Distribution of class labels after resampling {}\\n\".format(Counter(y_im)))\n",
    "            aplicar_modelos(X_im, y_im, file)\n",
    "        except ValueError as e:\n",
    "            file.write(f\"Skipping {imblearn.__class__.__name__} due to ERROR: {e}\\n\")\n",
    "        except RuntimeError as e:\n",
    "            file.write(f\"Skipping {imblearn.__class__.__name__} due to ERROR: {e}\\n\")\n",
    "\n",
    "# dividir en test y train df_gestures\n",
    "def split_df_gestures(df, target):\n",
    "    #---------Dividimos el dataset------------\n",
    "    # dividimos en variables independientes y en target\n",
    "    X = df.drop([target], axis=1)\n",
    "    y = df[target]\n",
    "\n",
    "    #---------Dividimos en train y test------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)    \n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [0, 1, 2, 4, 5, 6, 7, 8] #df['GestureLabel'].unique()\n",
    "\n",
    "with open('cvResults.txt', 'w') as file:\n",
    "    for gesture in gestures:\n",
    "        df_gesture = df[df['GestureLabel'] == gesture]\n",
    "        #---------Dividimos en train y test------------\n",
    "        X_train, X_test, y_train, y_test = split_df_gestures(df_gesture, 'CorrectLabel')  \n",
    "\n",
    "        file.write(f'\\n------------ CLASIFICACION GESTO {gesture} -----------\\n')\n",
    "        aplicar_imblearn(X_train, y_train, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline con hiperparametrizacion y feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ignorar los FitFileWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "\n",
    "# definimos el param_grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'balance_data__smote__k_neighbors': [2, 3, 4],\n",
    "        'reduce_dim__n_components': [0.8, 0.90, 1],\n",
    "        'classifier': [KNeighborsClassifier(n_neighbors=2)],\n",
    "        'classifier__n_neighbors': [2, 3, 5], \n",
    "        'classifier__weights': ['uniform', 'distance'], \n",
    "        'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  \n",
    "    },\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.7,0.8, 0.90, 1],\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [GaussianNB()]\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [SVC()],\n",
    "        'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'classifier__C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "\n",
    "        'reduce_dim__n_components': [0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    {\n",
    "\n",
    "        'reduce_dim__n_components': [0.7, 0.8, 0.90, 1],\n",
    "        'classifier': [LogisticRegression(max_iter=500)],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "]\n",
    "\n",
    "with open('resultsPipeline.txt', 'w') as file:\n",
    "    for gesture in df['GestureLabel'].unique():\n",
    "\n",
    "        df_gesture = df[df['GestureLabel'] == gesture]\n",
    "\n",
    "        #---------Dividimos en train y test------------\n",
    "        X_train, X_test, y_train, y_test = split_df_gestures(df_gesture)   \n",
    "        \n",
    "        file.write(f'\\n------------ CLASIFICACION GESTO {gesture} -----------\\n')\n",
    "        print(f'\\n------------ CLASIFICACION GESTO {gesture} -----------\\n')\n",
    "        pipeline = Pipeline([('balance_data',  SMOTETomek(smote=SMOTE(k_neighbors=2))),\n",
    "                            ('reduce_dim', PCA()),\n",
    "                            ('classifier', KNeighborsClassifier(n_neighbors=2))])\n",
    "\n",
    "        # Create the GridSearchCV object\n",
    "        grid = GridSearchCV(pipeline, param_grid)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_pipeline = grid.best_estimator_\n",
    "\n",
    "        file.write('Training set score: ' + str(best_pipeline.score(X_train, y_train)))\n",
    "        file.write('Test set score: ' + str(best_pipeline.score(X_test, y_test)))\n",
    "\n",
    "        print('Training set score: ' + str(best_pipeline.score(X_train, y_train)))\n",
    "        print('Test set score: ' + str(best_pipeline.score(X_test, y_test)))\n",
    "\n",
    "        globals()[f'best_pipe_{gesture}'] = best_pipeline\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
