{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1: Clasificación del movimiento\n",
    "\n",
    "**Descripción**\\\n",
    "En esta fase, se desarrollarán y evaluarán modelos de Machine Learning con el objetivo de predecir el gesto que está realizando un paciente.\n",
    "* Creación de Modelos: implementación y entrenamiento de modelos de clasificación para reconocer el tipo de gesto realizado por el paciente.\n",
    "* Evaluación de Modelos: evaluación del rendimiento de los modelos entrenados utilizando métricas específicas y disintas gráficas.\n",
    "\n",
    "**Entrada**\n",
    "* ``medidasPerRepetition.csv``: archivo en formato CSV que contiene cálculos estadísticos sobre los ángulos por repetición de cada sujeto. Este es el archivo de salida de *leer_dataset.ipynb*.\n",
    "\n",
    "**Salida**\n",
    "* ``modelo_fase1.sav``: archivo que guarda el pipeline completo de clasificación entrenado, incluyendo tanto el preprocesamiento como el modelo final.\n",
    "\n",
    "**Índice**\n",
    "1. [Preprocesado](#1-preprocesado)\n",
    "    - [Codificar variables](#11-codificar-variables)\n",
    "    - [Dividir el dataset](#12-dividir-el-dataset)\n",
    "2. [Modelos de ML](#2-modelos-de-ml)\n",
    "    - [Funciones creadas](#21-funciones-creadas)\n",
    "    - [Modelos con parámetros por defecto](#22-modelos-con-parámetros-por-defecto)\n",
    "    - [Hiperparametrización](#23-hipermetrización)\n",
    "    - [Selección de variables](#24-selección-de-variables)\n",
    "3. [Evaluación de los modelos](#3-evaluación-de-los-modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importar librerías---------\n",
    "# Manipular los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# scikit-learn (ML en python)\n",
    "## Procesar el dataset\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "## Modelos ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Evaluación de los modelos\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score, LearningCurveDisplay\n",
    "## Hiperparametrizacion\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "## Seleccion de variables\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "# Guardar modelos\n",
    "import joblib\n",
    "\n",
    "# Para ignorar los FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Importar los datos-----------\n",
    "# Dataframe medidas calculadas por repetición\n",
    "df = pd.read_csv('../Resultados/medidasPerRepetition.csv', dtype=object) # salida de leer_dataset.ipynb\n",
    "df.drop(['CorrectLabel'], axis=1,\n",
    "             inplace=True)\n",
    "df.head() # visualizacion de la cabecera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Codificar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Preparar el dataset-------\n",
    "df[\"Position\"] = df[\"Position\"].astype(str)\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df[[\"Position\"]])\n",
    "df[\"Position\"] = encoder.transform(df[[\"Position\"]])\n",
    "\n",
    "df = df.drop(['GestureName'], axis=1)\n",
    "\n",
    "# pasar variable obj to numeric\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dividir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dividir en test y train -----------\n",
    "# Selecciona los datos de prueba (varios sujetos)\n",
    "test_df = df.loc[(df.SubjectID==102) | (df.SubjectID==105) | (df.SubjectID==107) | (df.SubjectID==201) |\n",
    "            (df.SubjectID==202) | (df.SubjectID==205) | (df.SubjectID==211) |(df.SubjectID==301) | (df.SubjectID==302)] \n",
    "\n",
    "# Selecciona los datos de entrenamiento excluyendo los mismos sujetos\n",
    "train_df = df.loc[(df.SubjectID!=102) & (df.SubjectID!=105) & (df.SubjectID!=107) & (df.SubjectID!=201) &\n",
    "                (df.SubjectID!=202) & (df.SubjectID!=205) & (df.SubjectID!=211) & (df.SubjectID!=301) & (df.SubjectID!=302)]\n",
    "\n",
    "# ------- Dividir en target y variables ---------\n",
    "train_X = train_df.drop(['GestureLabel'], axis=1)\n",
    "train_y=pd.DataFrame(train_df['GestureLabel']) \n",
    "test_X= test_df.drop(['GestureLabel'], axis=1) \n",
    "test_y =pd.DataFrame(test_df['GestureLabel'])\n",
    "\n",
    "# Convertimos los df de target (y) a 1-d\n",
    "train_y = train_y.values.ravel()\n",
    "test_y = test_y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Funciones creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe para guardar los resultados\n",
    "test_result = pd.DataFrame({'Clasificadores': ['K-Neighbors',\n",
    "                                            'Decision tree',\n",
    "                                            'Naive Bayes',\n",
    "                                            'Suport Vector Machine',\n",
    "                                            'Random Forest']})\n",
    "\n",
    "#-------Funcion para evaluar los modelos-----------\n",
    "def test_models(modelos: list, tX: pd.DataFrame, ty: np.ndarray, df: pd.DataFrame, column_name: str):\n",
    "   \"\"\"\n",
    "   Evalúa una lista de modelos usando la métrica F1-score ponderada ('weighted') y\\\\\n",
    "   guarda los resultados en un DataFrame.\n",
    "\n",
    "   Parámetros\n",
    "   ----------\n",
    "   modelos : list\n",
    "      Lista de modelos a evaluar. Cada modelo debe implementar el método `.predict`.\n",
    "   tX : pd.DataFrame\n",
    "      Conjunto de datos de prueba con las características.\n",
    "   ty : np.ndarray\n",
    "      Array con los valores reales de la salida del conjunto de prueba.\n",
    "   df : pd.DataFrame\n",
    "      DataFrame donde se almacenarán los F1-scores resultantes.\n",
    "   column_name : str\n",
    "      Nombre de la columna en `df` donde se guardarán los resultados de la evaluación.\n",
    "   \"\"\"\n",
    "   new_evaluation = []\n",
    "   for modelo in modelos:\n",
    "      prediction = modelo.predict(tX) #  predicciones en los datos de prueba\n",
    "      report = classification_report(ty, prediction, zero_division=0) # informe de evaluación\n",
    "      score = f1_score(test_y, prediction, average='weighted') \n",
    "      new_evaluation.append(score)\n",
    "      print(f\"\\nModelo: {modelo.__class__.__name__}\") \n",
    "      print(report) \n",
    "   df.loc[:, column_name] = new_evaluation\n",
    "\n",
    "#-----------Función matriz de confusión-----\n",
    "def plot_confusion_matrix(modelo, tX: pd.DataFrame, ty: np.ndarray):\n",
    "    \"\"\"\n",
    "    Grafica la matriz de confusión para un modelo de clasificación dado.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    modelo : sklearn.base.BaseEstimator\n",
    "        El modelo de clasificación entrenado. Debe implementar el método `.predict`.\n",
    "    tX : pd.DataFrame\n",
    "        Conjunto de datos de prueba con las características.\n",
    "    ty : np.ndarray\n",
    "        Array con los valores reales de la salida del conjunto de prueb\n",
    "    \"\"\"\n",
    "    prediction = modelo.predict(tX)\n",
    "    cm = confusion_matrix(ty, prediction)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                     index = ['EFL','EFR','SFL', 'SFR', 'SAL',\n",
    "                              'SAR', 'SFE', 'STL', 'STR'], \n",
    "                     columns = ['EFL','EFR','SFL', 'SFR', 'SAL',\n",
    "                              'SAR', 'SFE', 'STL', 'STR'])\n",
    "    ax = sns.heatmap(cm_df, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "    ax.set_title(f'Matriz de confusión {modelo.__class__.__name__}')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modelos con parámetros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------intanciar modelos de ML----------\n",
    "knn = KNeighborsClassifier() # K-Neighbors classifier\n",
    "dtree = DecisionTreeClassifier() # Decision tree\n",
    "nb = GaussianNB() # Naive Bayes\n",
    "svm = SVC() # Suport Vector Machine\n",
    "rf = RandomForestClassifier()  # Random Forest\n",
    "\n",
    "#--------entrenamiento de los modelos----------\n",
    "models = [knn, dtree, nb, svm, rf]\n",
    "\n",
    "for modelo in models:\n",
    "    modelo.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Curvas de apendizaje -------------\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 14))\n",
    "\n",
    "common_params = {\n",
    "    \"X\": train_X,\n",
    "    \"y\": train_y,\n",
    "    \"groups\": train_X['SubjectID'],\n",
    "    \"cv\": LeaveOneGroupOut(),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 4,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"f1_weighted\",\n",
    "}\n",
    "for idx, estimator in enumerate(models):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "    handles, label = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[:2], [\"Resultado del entrenamiento\",\n",
    "                            \"Resultado de la validación\"])\n",
    "    ax.set_title(f\"Curva de aprendizaje de {estimator.__class__.__name__}\")\n",
    "    ax.set_ylim(0, 1.05)\n",
    "fig.delaxes(axes.flatten()[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Métricas de evaluación ---------\n",
    "test_models(models, test_X, test_y, test_result, 'Modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Matriz de confusión --------\n",
    "plot_confusion_matrix(rf, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Hipermetrización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- Mallas de Parametros ---------------\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [6, 7, 8],\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'leaf_size': (3, 4, 5, 6, 8),\n",
    "    'p': (1,2),\n",
    "    'metric': ('minkowski', 'chebyshev')\n",
    "}\n",
    "\n",
    "param_grid_dtree = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 40, 50, 60],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 7],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_nb = {'var_smoothing': np.logspace(0, -8, num=100)}\n",
    "\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 0.2, 0.3],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 50, 60],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 5, 6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Aplicar hiperparametrización ---------------\n",
    "\n",
    "# cv con LeaveOneGroupOut\n",
    "logo = LeaveOneGroupOut()\n",
    "subject_ids = train_X['SubjectID'] # para los grupos\n",
    "\n",
    "# crear los modelos con GridSearchCV\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=logo,\n",
    "                      scoring='f1_weighted', n_jobs=-1)\n",
    "gs_dtree = GridSearchCV(DecisionTreeClassifier(), param_grid_dtree, cv=logo,\n",
    "                        scoring='f1_weighted', n_jobs=-1)\n",
    "gs_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=logo,\n",
    "                     scoring='f1_weighted', n_jobs=-1)\n",
    "gs_svm = GridSearchCV(SVC(), param_grid_svm, cv=logo,\n",
    "                      scoring='f1_weighted', n_jobs=-1)\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=logo,\n",
    "                           scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "modelos = [gs_knn, gs_dtree, gs_nb, gs_svm, gs_rf]\n",
    "\n",
    "best_models = []\n",
    "for modelo in modelos:\n",
    "    # entrenar\n",
    "    modelo.fit(train_X, train_y, groups=subject_ids)\n",
    "    best_modelo = modelo.best_estimator_\n",
    "    # imprimir resultado\n",
    "    print(f\"\\nModelo: {modelo.estimator.__class__.__name__}\") \n",
    "    print(\"Mejores parámetros: \", modelo.best_params_)\n",
    "    print(\"Mejor resultado: \", modelo.best_score_)\n",
    "    best_models.append(best_modelo)\n",
    "    # curvas de apendizaje\n",
    "    plt.figure(figsize=(6,4))\n",
    "    LearningCurveDisplay.from_estimator(best_modelo, \n",
    "                                        X=train_X,\n",
    "                                        y=train_y,\n",
    "                                        groups=subject_ids,\n",
    "                                        cv=logo,\n",
    "                                        score_type=\"both\",\n",
    "                                        n_jobs=4,\n",
    "                                        line_kw={\"marker\": \"o\"},\n",
    "                                        std_display_style=\"fill_between\",\n",
    "                                        score_name=\"f1_weighted\"\n",
    "                                    )\n",
    "        \n",
    "    plt.legend([\"Resultado del entrenamiento\", \"Resultado de la validación\"])\n",
    "    plt.title(f\"Curva de aprendizaje de {modelo.estimator.__class__.__name__}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Evaluación de los modelos --------\n",
    "test_models(best_models, test_X, test_y, test_result, 'Hiperparametrización (H)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Matriz de confusión de RF ---------\n",
    "plot_confusion_matrix(best_models[4], test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.1 SelectKBest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cunata que la columna *SubjectID* debe de estar en dataframe final para poder hacer los gurpos al realizar la validación cruzada con *LeaveOneGroupOut()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = train_X['SubjectID']\n",
    "\n",
    "# Definimos feature Selection K=50 (selecciona entonces las 50 variables que considere mas importantes)\n",
    "feature_selection = SelectKBest(k=50)\n",
    "\n",
    "# Fit Feature Selection (entrena y hace una tranformada)\n",
    "selected_features = feature_selection.fit_transform(train_X.drop(columns=['SubjectID']), train_y)\n",
    "\n",
    "# Selecionamos las características mas relevantes para nuestro problema\n",
    "selected = feature_selection.get_support(indices=True)\n",
    "\n",
    "print(train_X.columns[selected])\n",
    "\n",
    "# Reduce train_X to the selected features with .transform(X)\n",
    "# esto elimina las variales que no nos intersan.\n",
    "\n",
    "X_fs = pd.DataFrame(selected_features,\n",
    "                 columns=train_X.drop(columns=['SubjectID']).columns[selected])\n",
    "\n",
    "X_fs['SubjectID'] = subject_id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Entrenar con variables seleccionadas ----------\n",
    "knn_fs = KNeighborsClassifier() # K-Neighbors classifier\n",
    "dtree_fs = DecisionTreeClassifier() # Decision tree\n",
    "nb_fs = GaussianNB() # Naive Bayes\n",
    "svm_fs = SVC() # Suport Vector Machine\n",
    "rf_fs = RandomForestClassifier()  # Random Forest\n",
    "\n",
    "models_fs = [knn_fs, dtree_fs, nb_fs, svm_fs, rf_fs]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "for modelo in models_fs:\n",
    "        print(f\"\\nModelo: {modelo.__class__.__name__}\")\n",
    "        modelo.fit(X_fs, train_y)\n",
    "        scores = cross_val_score(modelo, X_fs, train_y, groups=X_fs['SubjectID'], \n",
    "                                 scoring='f1_weighted', cv=logo)\n",
    "        print(\"%0.2f F1 score con una derivación estandar de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Transformar el conjunto de test y evaluación -----------\n",
    "test_subject_id = test_X['SubjectID']\n",
    "\n",
    "selected_features_test = feature_selection.transform(test_X.drop(columns=['SubjectID']))\n",
    "\n",
    "X_fs_test = pd.DataFrame(selected_features_test,\n",
    "                         columns=test_X.drop(columns=['SubjectID']).columns[selected])\n",
    "\n",
    "X_fs_test['SubjectID'] = test_subject_id.values\n",
    "\n",
    "test_models(models_fs, X_fs_test, test_y, test_result, 'Selección de variables (FS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Matriz de confusión -------------\n",
    "plot_confusion_matrix(rf_fs, X_fs_test, test_y,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.2 Modelos con hiperparametrización y selección de variables**\n",
    "\n",
    "Entrenar los modelos a los cuales se la ha realizado el ajuste de hiperparámetros con las variables seleccionadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar los modelos\n",
    "for modelo in best_models:\n",
    "    modelo.fit(X_fs, train_y)\n",
    "\n",
    "# Evaluación\n",
    "test_models(best_models, X_fs_test, test_y, test_result, 'H + Fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Matriz de confusión de RF -------------------\n",
    "plot_confusion_matrix(best_models[4], X_fs_test, test_y)\n",
    "mejores_parametros = best_models[4].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.3 Recursive feature elimination**\n",
    "\n",
    "Selección de varaibles con RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos a los que se puede aplicar RFECV\n",
    "dtree_rfe = DecisionTreeClassifier() # Decision tree\n",
    "rf_rfe = RandomForestClassifier(n_estimators = 5)  # Random Forest\n",
    "\n",
    "models_with_coef = [dtree_rfe, rf_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Aplicar RFECV ----------\n",
    "for model in models_with_coef:\n",
    "    rfecv = RFECV(\n",
    "            estimator=model,\n",
    "        scoring=\"f1_weighted\",\n",
    "        cv = LeaveOneGroupOut(),\n",
    "        n_jobs=-1 \n",
    "    )\n",
    "    # entrenar\n",
    "    rfecv.fit(train_X, train_y, groups=train_X['SubjectID'])\n",
    "    # mostrar resultados\n",
    "    print(f\"\\nModelo: {rfecv.estimator.__class__.__name__}\") \n",
    "    print(f\"Número óptimo de características: {rfecv.n_features_}\")\n",
    "    selected = rfecv.get_feature_names_out()\n",
    "    print(selected)\n",
    "    print(f'Evaluación: {rfecv.score(test_X, test_y)}')\n",
    "    # mostrar gráfica\n",
    "    cv_results = pd.DataFrame(rfecv.cv_results_)\n",
    "    plt.title(f\"RFECV {rfecv.estimator.__class__.__name__}\")\n",
    "    plt.xlabel(\"Número de características\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    plt.plot(range(1, len(cv_results['mean_test_score']) + 1),\n",
    "             cv_results['mean_test_score'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Dataframe con los f1-scores ------\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Gráfica comparativa -------\n",
    "x_labels = ['Modelos', 'Hiperparametrización (H)', 'Selección de variables (FS)', 'H + Fs']\n",
    "df_melted = pd.melt(test_result, id_vars=['Clasificadores'], value_vars=x_labels,\n",
    "                    var_name='score_type', value_name='score')\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.lineplot(x='score_type', y='score', hue='Clasificadores',\n",
    "                  data=df_melted, marker='o', palette='Set1')\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-Scores por Clasificador')\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un pipeline con la codificacion de varibales, seleccion de características y el mejor modelo, y guardarlo con joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_data = pd.read_csv('../Resultados/medidasPerRepetition.csv', dtype=object) # salida de leer_dataset.ipynb\n",
    "\n",
    "# ------- Dividir en target y variables ---------\n",
    "df_data = df_data.apply(pd.to_numeric, errors='ignore')\n",
    "df_data.drop(['GestureName', 'CorrectLabel'], axis=1, inplace=True)\n",
    "\n",
    "X = df_data.drop(['GestureLabel'], axis=1)\n",
    "y = pd.DataFrame(df_data['GestureLabel']) \n",
    "# Convertimos los df de target (y) a 1-d\n",
    "y = y.values.ravel()\n",
    "\n",
    "filename = '../Resultados/modelo_fase1.sav'\n",
    "pipeline = Pipeline([\n",
    "                      ('preprocessing', ColumnTransformer(\n",
    "                            transformers=[('encoder', OrdinalEncoder(), ['Position'])],\n",
    "                            remainder='passthrough' ),\n",
    "                        ),\n",
    "  \n",
    "                     ('feature_selection', SelectKBest(k=50)),\n",
    "                     ('classifier', RandomForestClassifier(**mejores_parametros))\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "joblib.dump(pipeline, filename)\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
